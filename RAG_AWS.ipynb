{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RWcbEslRPnX",
    "outputId": "2cca712c-df44-4c56-de14-57dd86f87f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (1.40.27)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.27 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (from boto3) (1.40.27)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (from botocore<1.41.0,>=1.40.27->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (from botocore<1.41.0,>=1.40.27->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\natdh\\documents\\aws_workshop\\.venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.27->boto3) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xydbkoXQ2sQZ"
   },
   "source": [
    "### retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kn6e7AJM2apx",
    "outputId": "2b7e4a35-2f82-4bcb-8b3d-a61416cfd2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FXFXKMJZNW: 5 results\n",
      "\n",
      "üíæ Saved results to kb_retrievals.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "KNOWLEDGE_BASE_LIST = [\"FXFXKMJZNW\"]\n",
    "QUERY_TEXT = \"‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡∏£‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥\"\n",
    "NUMBER_OF_RESULTS = 5\n",
    "AWS_REGION = \"us-east-1\"\n",
    "OUTPUT_FILE = \"kb_retrievals.json\"\n",
    "\n",
    "# ============================================================\n",
    "# üîπ FUNCTION: Retrieve results from multiple Knowledge Bases\n",
    "# ============================================================\n",
    "def retrieve_for_kbs(kb_list, query, num_results, region, profile_name=None):\n",
    "    # Create session with profile if specified\n",
    "    if profile_name:\n",
    "        session = boto3.Session(profile_name=profile_name)\n",
    "        client = session.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "    else:\n",
    "        client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for kb in kb_list:\n",
    "        try:\n",
    "            resp = client.retrieve(\n",
    "                knowledgeBaseId=kb,\n",
    "                retrievalQuery={\"text\": query},\n",
    "                retrievalConfiguration={\n",
    "                    \"vectorSearchConfiguration\": {\"numberOfResults\": num_results}\n",
    "                },\n",
    "            )\n",
    "\n",
    "            hits = resp.get(\"retrievalResults\", [])[:num_results]\n",
    "            parsed = []\n",
    "\n",
    "            for h in hits:\n",
    "                loc = h.get(\"location\", {}) or {}\n",
    "                ltype = loc.get(\"type\")\n",
    "\n",
    "                if ltype == \"S3\":\n",
    "                    source = loc.get(\"s3Location\", {}).get(\"uri\")\n",
    "                elif ltype == \"WEB\":\n",
    "                    source = loc.get(\"webLocation\", {}).get(\"url\")\n",
    "                else:\n",
    "                    source = loc\n",
    "\n",
    "                parsed.append({\n",
    "                    \"text\": h.get(\"content\", {}).get(\"text\", \"\"),\n",
    "                    \"source\": source,\n",
    "                    \"score\": h.get(\"score\"),\n",
    "                })\n",
    "\n",
    "            out[kb] = {\n",
    "                \"query\": query,\n",
    "                \"region\": region,\n",
    "                \"count\": len(parsed),\n",
    "                \"results\": parsed,\n",
    "            }\n",
    "\n",
    "            print(f\"‚úÖ {kb}: {len(parsed)} results\")\n",
    "\n",
    "        except Exception as e:\n",
    "            out[kb] = {\"error\": str(e)}\n",
    "            print(f\"‚ùå {kb}: error -> {e}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# üîπ MAIN EXECUTION\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    results = retrieve_for_kbs(\n",
    "        KNOWLEDGE_BASE_LIST,\n",
    "        QUERY_TEXT,\n",
    "        NUMBER_OF_RESULTS,\n",
    "        AWS_REGION,\n",
    "    )\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nüíæ Saved results to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfcX66of2xio"
   },
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PS35CYtS3NYp"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'kb_retrievals.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c2Nn7JM825qb",
    "outputId": "de6bf8f5-b192-4a1c-c4d5-67adad975df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "üîé QUERY TEXT: ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡∏£‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥\n",
      "=========================================================\n",
      "\n",
      "üìò Knowledge Base ID: FXFXKMJZNW | Name: defaultchunk\n",
      "--------------------------------------------------\n",
      "Barrow , 2002 ) ‡∏ã‡∏∂‡πà‡∏á‡∏•‡∏π‡∏Å‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏°‡πá‡∏î‡∏Ç‡∏ô‡∏≤‡∏î 0.1 ‡∏°‡∏¥‡∏•‡∏•‡∏¥‡πÄ‡∏°‡∏ï‡∏£ (Moren et al., 2011) ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥‡∏£‡∏∞‡∏¢‡∏∞‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï\n",
      "‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏¥‡∏ï‡∏Ç‡∏∂‡πâ‡∏ô (Concei√ßao et al., 2010) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ö‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á ‡∏°‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏û‡∏á ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ (\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import textwrap\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "QUERY_TEXT = \"‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡∏£‡∏á‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ç‡∏≠‡∏á‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥\"\n",
    "\n",
    "retrieved_data = data\n",
    "\n",
    "#KNOWLEDGE_BASE_LIST = [\"1UUZMNH8CP\", \"EBJHRCUOQ2\", \"MTZLVXWABU\"]\n",
    "knowledge_base_map = {\n",
    "    \"FXFXKMJZNW\": \"defaultchunk\",\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# üîπ DISPLAY RESULTS\n",
    "# ============================================================\n",
    "print(\"=========================================================\")\n",
    "print(f\"üîé QUERY TEXT: {QUERY_TEXT}\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "for kb_id, kb_name in knowledge_base_map.items():\n",
    "    if kb_id in retrieved_data and retrieved_data[kb_id][\"results\"]:\n",
    "        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å Chunk ‡πÅ‡∏£‡∏Å (index 0)\n",
    "        chunk_text = retrieved_data[kb_id][\"results\"][0][\"text\"]\n",
    "\n",
    "        # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 180 ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞\n",
    "        wrapped_text = textwrap.fill(chunk_text, width=180)\n",
    "\n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        print(f\"\\nüìò Knowledge Base ID: {kb_id} | Name: {kb_name}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(wrapped_text)\n",
    "    else:\n",
    "        print(f\"\\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {kb_id} ({kb_name})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7r1mfVAAS0d"
   },
   "source": [
    "## Example 2 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Specific/Factual Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDnIq_gYAS0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FXFXKMJZNW: 5 results\n",
      "\n",
      "üíæ Saved results to kb_retrievals2.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "KNOWLEDGE_BASE_LIST = [\"FXFXKMJZNW\"]\n",
    "QUERY_TEXT = \"‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏õ‡∏•‡∏≤‡∏ô‡∏¥‡∏•‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå\"\n",
    "NUMBER_OF_RESULTS = 5\n",
    "AWS_REGION = \"us-east-1\"\n",
    "OUTPUT_FILE = \"kb_retrievals2.json\"\n",
    "\n",
    "# ============================================================\n",
    "# üîπ FUNCTION: Retrieve results from multiple Knowledge Bases\n",
    "# ============================================================\n",
    "def retrieve_for_kbs(kb_list, query, num_results, region, profile_name=None):\n",
    "    # Create session with profile if specified\n",
    "    if profile_name:\n",
    "        session = boto3.Session(profile_name=profile_name)\n",
    "        client = session.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "    else:\n",
    "        client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for kb in kb_list:\n",
    "        try:\n",
    "            resp = client.retrieve(\n",
    "                knowledgeBaseId=kb,\n",
    "                retrievalQuery={\"text\": query},\n",
    "                retrievalConfiguration={\n",
    "                    \"vectorSearchConfiguration\": {\"numberOfResults\": num_results}\n",
    "                },\n",
    "            )\n",
    "\n",
    "            hits = resp.get(\"retrievalResults\", [])[:num_results]\n",
    "            parsed = []\n",
    "\n",
    "            for h in hits:\n",
    "                loc = h.get(\"location\", {}) or {}\n",
    "                ltype = loc.get(\"type\")\n",
    "\n",
    "                if ltype == \"S3\":\n",
    "                    source = loc.get(\"s3Location\", {}).get(\"uri\")\n",
    "                elif ltype == \"WEB\":\n",
    "                    source = loc.get(\"webLocation\", {}).get(\"url\")\n",
    "                else:\n",
    "                    source = loc\n",
    "\n",
    "                parsed.append({\n",
    "                    \"text\": h.get(\"content\", {}).get(\"text\", \"\"),\n",
    "                    \"source\": source,\n",
    "                    \"score\": h.get(\"score\"),\n",
    "                })\n",
    "\n",
    "            out[kb] = {\n",
    "                \"query\": query,\n",
    "                \"region\": region,\n",
    "                \"count\": len(parsed),\n",
    "                \"results\": parsed,\n",
    "            }\n",
    "\n",
    "            print(f\"‚úÖ {kb}: {len(parsed)} results\")\n",
    "\n",
    "        except Exception as e:\n",
    "            out[kb] = {\"error\": str(e)}\n",
    "            print(f\"‚ùå {kb}: error -> {e}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# üîπ MAIN EXECUTION\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    results = retrieve_for_kbs(\n",
    "        KNOWLEDGE_BASE_LIST,\n",
    "        QUERY_TEXT,\n",
    "        NUMBER_OF_RESULTS,\n",
    "        AWS_REGION,\n",
    "    )\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nüíæ Saved results to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c9GBZfUpAS0e"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'kb_retrievals.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Filc7vQFAS0f",
    "outputId": "b788d91d-5737-4cc2-be19-89ec3c0ec232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "üîé QUERY TEXT: ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏õ‡∏•‡∏≤‡∏ô‡∏¥‡∏•‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå\n",
      "=========================================================\n",
      "\n",
      "üìò Knowledge Base ID: FXFXKMJZNW | Name: defaultchunk\n",
      "--------------------------------------------------\n",
      "Barrow , 2002 ) ‡∏ã‡∏∂‡πà‡∏á‡∏•‡∏π‡∏Å‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏°‡πá‡∏î‡∏Ç‡∏ô‡∏≤‡∏î 0.1 ‡∏°‡∏¥‡∏•‡∏•‡∏¥‡πÄ‡∏°‡∏ï‡∏£ (Moren et al., 2011) ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥‡∏£‡∏∞‡∏¢‡∏∞‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï\n",
      "‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏¥‡∏ï‡∏Ç‡∏∂‡πâ‡∏ô (Concei√ßao et al., 2010) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ö‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏°‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á ‡∏°‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏û‡∏á ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ (\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import textwrap\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "QUERY_TEXT = \"‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏õ‡∏•‡∏≤‡∏ô‡∏¥‡∏•‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå\"\n",
    "\n",
    "retrieved_data = data\n",
    "\n",
    "#KNOWLEDGE_BASE_LIST = [\"1UUZMNH8CP\", \"EBJHRCUOQ2\", \"MTZLVXWABU\"]\n",
    "knowledge_base_map = {\n",
    "    \"FXFXKMJZNW\": \"defaultchunk\",\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# üîπ DISPLAY RESULTS\n",
    "# ============================================================\n",
    "print(\"=========================================================\")\n",
    "print(f\"üîé QUERY TEXT: {QUERY_TEXT}\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "for kb_id, kb_name in knowledge_base_map.items():\n",
    "    if kb_id in retrieved_data and retrieved_data[kb_id][\"results\"]:\n",
    "        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å Chunk ‡πÅ‡∏£‡∏Å (index 0)\n",
    "        chunk_text = retrieved_data[kb_id][\"results\"][0][\"text\"]\n",
    "\n",
    "        # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 180 ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞\n",
    "        wrapped_text = textwrap.fill(chunk_text, width=180)\n",
    "\n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        print(f\"\\nüìò Knowledge Base ID: {kb_id} | Name: {kb_name}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(wrapped_text)\n",
    "    else:\n",
    "        print(f\"\\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {kb_id} ({kb_name})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca6VpnTwAS0g"
   },
   "source": [
    "## Example3 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (Conceptual/Method Query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rw1Ga7jNAS0h",
    "outputId": "a01f8114-d8be-4e43-bc91-ff1073af5071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FXFXKMJZNW: 5 results\n",
      "\n",
      "üíæ Saved results to kb_retrievals3.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "KNOWLEDGE_BASE_LIST = [\"FXFXKMJZNW\"]\n",
    "QUERY_TEXT = \"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏£‡πå‡∏™‡∏±‡∏ô\"\n",
    "NUMBER_OF_RESULTS = 5\n",
    "AWS_REGION = \"us-east-1\"\n",
    "OUTPUT_FILE = \"kb_retrievals3.json\"\n",
    "\n",
    "# ============================================================\n",
    "# üîπ FUNCTION: Retrieve results from multiple Knowledge Bases\n",
    "# ============================================================\n",
    "def retrieve_for_kbs(kb_list, query, num_results, region, profile_name=None):\n",
    "    # Create session with profile if specified\n",
    "    if profile_name:\n",
    "        session = boto3.Session(profile_name=profile_name)\n",
    "        client = session.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "    else:\n",
    "        client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for kb in kb_list:\n",
    "        try:\n",
    "            resp = client.retrieve(\n",
    "                knowledgeBaseId=kb,\n",
    "                retrievalQuery={\"text\": query},\n",
    "                retrievalConfiguration={\n",
    "                    \"vectorSearchConfiguration\": {\"numberOfResults\": num_results}\n",
    "                },\n",
    "            )\n",
    "\n",
    "            hits = resp.get(\"retrievalResults\", [])[:num_results]\n",
    "            parsed = []\n",
    "\n",
    "            for h in hits:\n",
    "                loc = h.get(\"location\", {}) or {}\n",
    "                ltype = loc.get(\"type\")\n",
    "\n",
    "                if ltype == \"S3\":\n",
    "                    source = loc.get(\"s3Location\", {}).get(\"uri\")\n",
    "                elif ltype == \"WEB\":\n",
    "                    source = loc.get(\"webLocation\", {}).get(\"url\")\n",
    "                else:\n",
    "                    source = loc\n",
    "\n",
    "                parsed.append({\n",
    "                    \"text\": h.get(\"content\", {}).get(\"text\", \"\"),\n",
    "                    \"source\": source,\n",
    "                    \"score\": h.get(\"score\"),\n",
    "                })\n",
    "\n",
    "            out[kb] = {\n",
    "                \"query\": query,\n",
    "                \"region\": region,\n",
    "                \"count\": len(parsed),\n",
    "                \"results\": parsed,\n",
    "            }\n",
    "\n",
    "            print(f\"‚úÖ {kb}: {len(parsed)} results\")\n",
    "\n",
    "        except Exception as e:\n",
    "            out[kb] = {\"error\": str(e)}\n",
    "            print(f\"‚ùå {kb}: error -> {e}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# üîπ MAIN EXECUTION\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    results = retrieve_for_kbs(\n",
    "        KNOWLEDGE_BASE_LIST,\n",
    "        QUERY_TEXT,\n",
    "        NUMBER_OF_RESULTS,\n",
    "        AWS_REGION,\n",
    "    )\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nüíæ Saved results to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ki9LzcMWAS0i"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'kb_retrievals3.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uXfEbGc6AS0j",
    "outputId": "c5596f5e-c8e1-4217-d9e0-9a9ea82545c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "üîé QUERY TEXT: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏£‡πå‡∏™‡∏±‡∏ô\n",
      "=========================================================\n",
      "\n",
      "üìò Knowledge Base ID: FXFXKMJZNW | Name: defaultchunk\n",
      "--------------------------------------------------\n",
      "‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏£‡πå‡∏™‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á ‡∏û‡∏µ‡∏ä‡∏Ñ‡∏ì‡∏¥‡∏ï ‡∏à‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏ô‡∏¥‡∏î‡πÉ‡∏ô‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£\n",
      "‡∏ï‡∏•‡∏≠‡∏î‡∏à‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ô‡πâ‡∏≥‡∏°‡∏µ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏™‡∏°‡∏≠‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏• ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß\n",
      "‡∏à‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏≠‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import textwrap\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "# QUERY_TEXT = \"‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡∏π‡∏Å‡∏õ‡∏•‡∏≤‡∏ô‡∏¥‡∏•‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå\"\n",
    "\n",
    "retrieved_data = data\n",
    "\n",
    "#KNOWLEDGE_BASE_LIST = [\"1UUZMNH8CP\", \"EBJHRCUOQ2\", \"MTZLVXWABU\"]\n",
    "knowledge_base_map = {\n",
    "    \"FXFXKMJZNW\": \"defaultchunk\",\n",
    "\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# üîπ DISPLAY RESULTS\n",
    "# ============================================================\n",
    "print(\"=========================================================\")\n",
    "print(f\"üîé QUERY TEXT: {QUERY_TEXT}\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "for kb_id, kb_name in knowledge_base_map.items():\n",
    "    if kb_id in retrieved_data and retrieved_data[kb_id][\"results\"]:\n",
    "        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å Chunk ‡πÅ‡∏£‡∏Å (index 0)\n",
    "        chunk_text = retrieved_data[kb_id][\"results\"][0][\"text\"]\n",
    "\n",
    "        # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 180 ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞\n",
    "        wrapped_text = textwrap.fill(chunk_text, width=180)\n",
    "\n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        print(f\"\\nüìò Knowledge Base ID: {kb_id} | Name: {kb_name}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(wrapped_text)\n",
    "    else:\n",
    "        print(f\"\\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: {kb_id} ({kb_name})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziwQnJMaAS0m"
   },
   "source": [
    "## Example5 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á (Table-based Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3738K0VHAS0r",
    "outputId": "7614632a-8083-4a08-b990-0f2162582ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FXFXKMJZNW: 1 results\n",
      "\n",
      "üíæ Saved results to kb_retrievals5.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ IMPORTS\n",
    "# ============================================================\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CONFIGURATION\n",
    "# ============================================================\n",
    "KNOWLEDGE_BASE_LIST = [\"FXFXKMJZNW\"]\n",
    "QUERY_TEXT = \"‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏Å‡∏ñ‡∏±‡πà‡∏ß‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏õ‡∏•‡∏≤‡∏Å‡∏¥‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà\"\n",
    "NUMBER_OF_RESULTS = 1\n",
    "AWS_REGION = \"us-east-1\"\n",
    "OUTPUT_FILE = \"kb_retrievals5.json\"\n",
    "\n",
    "# ============================================================\n",
    "# üîπ FUNCTION: Retrieve results from multiple Knowledge Bases\n",
    "# ============================================================\n",
    "def retrieve_for_kbs(kb_list, query, num_results, region, profile_name=None):\n",
    "    # Create session with profile if specified\n",
    "    if profile_name:\n",
    "        session = boto3.Session(profile_name=profile_name)\n",
    "        client = session.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "    else:\n",
    "        client = boto3.client(\"bedrock-agent-runtime\", region_name=region)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for kb in kb_list:\n",
    "        try:\n",
    "            resp = client.retrieve(\n",
    "                knowledgeBaseId=kb,\n",
    "                retrievalQuery={\"text\": query},\n",
    "                retrievalConfiguration={\n",
    "                    \"vectorSearchConfiguration\": {\"numberOfResults\": num_results}\n",
    "                },\n",
    "            )\n",
    "\n",
    "            hits = resp.get(\"retrievalResults\", [])[:num_results]\n",
    "            parsed = []\n",
    "\n",
    "            for h in hits:\n",
    "                loc = h.get(\"location\", {}) or {}\n",
    "                ltype = loc.get(\"type\")\n",
    "\n",
    "                if ltype == \"S3\":\n",
    "                    source = loc.get(\"s3Location\", {}).get(\"uri\")\n",
    "                elif ltype == \"WEB\":\n",
    "                    source = loc.get(\"webLocation\", {}).get(\"url\")\n",
    "                else:\n",
    "                    source = loc\n",
    "\n",
    "                parsed.append({\n",
    "                    \"text\": h.get(\"content\", {}).get(\"text\", \"\"),\n",
    "                    \"source\": source,\n",
    "                    \"score\": h.get(\"score\"),\n",
    "                })\n",
    "\n",
    "            out[kb] = {\n",
    "                \"query\": query,\n",
    "                \"region\": region,\n",
    "                \"count\": len(parsed),\n",
    "                \"results\": parsed,\n",
    "            }\n",
    "\n",
    "            print(f\"‚úÖ {kb}: {len(parsed)} results\")\n",
    "\n",
    "        except Exception as e:\n",
    "            out[kb] = {\"error\": str(e)}\n",
    "            print(f\"‚ùå {kb}: error -> {e}\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# üîπ MAIN EXECUTION\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    results = retrieve_for_kbs(\n",
    "        KNOWLEDGE_BASE_LIST,\n",
    "        QUERY_TEXT,\n",
    "        NUMBER_OF_RESULTS,\n",
    "        AWS_REGION,\n",
    "    )\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nüíæ Saved results to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Gc1amt2RAS0t"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'kb_retrievals5.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNBaXb5HAS0u",
    "outputId": "37b72f0f-78b1-420c-ed0e-060538067af0"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîπ RAG PIPELINE WITH CONCEPTUAL QUERY\n",
    "# ============================================================\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def rag_pipeline(query, knowledge_base_id, num_results=5):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve + Generate\n",
    "    \n",
    "    Args:\n",
    "        query: User's question\n",
    "        knowledge_base_id: AWS Bedrock Knowledge Base ID\n",
    "        num_results: Number of chunks to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains query, retrieved chunks, and generated answer\n",
    "    \"\"\"\n",
    "    # Initialize clients\n",
    "    bedrock_agent = boto3.client(\"bedrock-agent-runtime\", region_name=\"us-east-1\")\n",
    "    bedrock = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üîç Query: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Step 1: Retrieve from Knowledge Base\n",
    "    retrieve_resp = bedrock_agent.retrieve(\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        retrievalQuery={\"text\": query},\n",
    "        retrievalConfiguration={\n",
    "            \"vectorSearchConfiguration\": {\"numberOfResults\": num_results}\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    results = retrieve_resp.get(\"retrievalResults\", [])\n",
    "    contexts = [r.get(\"content\", {}).get(\"text\", \"\") for r in results]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Retrieved {len(results)} chunks\")\n",
    "    \n",
    "    # Step 2: Build prompt with context\n",
    "    context_text = \"\\n\\n\".join([f\"[Document {i+1}]\\n{txt}\" for i, txt in enumerate(contexts)])\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert assistant in aquaculture and aquatic animal husbandry. Answer questions based ONLY on the provided context from Thai aquaculture documentation.\n",
    "\n",
    "Reference Information:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Instructions:\n",
    "- Answer in Thai language only\n",
    "- Base your answer strictly on the provided context\n",
    "- Be clear, concise, and accurate\n",
    "- If the context doesn't contain enough information to answer, state this clearly\n",
    "- Use proper aquaculture terminology in Thai\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Step 3: Generate answer with Claude\n",
    "    request = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=\"global.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
    "        body=json.dumps(request)\n",
    "    )\n",
    "    \n",
    "    answer = json.loads(response['body'].read())['content'][0]['text']\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ü§ñ ANSWER FROM CLAUDE SONNET 4.5:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(answer)\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_chunks\": len(results),\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "# Test with different query\n",
    "result = rag_pipeline(\n",
    "    query=\"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏£‡πå‡∏™‡∏±‡∏ô\",\n",
    "    knowledge_base_id=\"FXFXKMJZNW\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
